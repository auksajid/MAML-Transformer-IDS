{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7srNnNmZqov"
      },
      "outputs": [],
      "source": [
        "def run_demo(data_path=None, dataset_name=\"synthetic\"):\n",
        "    \"\"\"Run a complete demo of the MAML transformer for network intrusion detection\"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"MAML Transformer for Network Intrusion Detection - Demo\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Step 1: Data preparation\n",
        "    print(\"\\n1. Loading and preprocessing data...\")\n",
        "    data_processor = NetworkDataProcessor(data_path)\n",
        "\n",
        "    if dataset_name == \"synthetic\":\n",
        "        df = data_processor._generate_synthetic_data(n_samples=10000)\n",
        "    else:\n",
        "        df = data_processor.load_data(dataset_name)\n",
        "\n",
        "    X, y_binary, y_multiclass = data_processor.preprocess_data(df)\n",
        "\n",
        "    print(f\"Total samples: {len(X)}\")\n",
        "    print(f\"Features: {X.shape[1]}\")\n",
        "    if y_multiclass is not None:\n",
        "        print(f\"Number of attack classes: {len(np.unique(y_multiclass))}\")\n",
        "    print(f\"Attack samples: {np.sum(y_binary)}\")\n",
        "    print(f\"Normal samples: {len(y_binary) - np.sum(y_binary)}\")\n",
        "\n",
        "    # Step 2: Create tasks for meta-learning\n",
        "    print(\"\\n2. Creating few-shot learning tasks...\")\n",
        "    if y_multiclass is not None:\n",
        "        all_tasks = data_processor.create_tasks(X, y_multiclass, num_tasks=200, k_shot=5, query_size=15)\n",
        "\n",
        "        # Split into train, validation and test tasks\n",
        "        num_train = int(len(all_tasks) * 0.7)\n",
        "        num_val = int(len(all_tasks) * 0.15)\n",
        "\n",
        "        train_tasks = all_tasks[:num_train]\n",
        "        val_tasks = all_tasks[num_train:num_train+num_val]\n",
        "        test_tasks = all_tasks[num_train+num_val:]\n",
        "\n",
        "        print(f\"Number of training tasks: {len(train_tasks)}\")\n",
        "        print(f\"Number of validation tasks: {len(val_tasks)}\")\n",
        "        print(f\"Number of test tasks: {len(test_tasks)}\")\n",
        "    else:\n",
        "        print(\"Multiclass labels not available. Cannot create few-shot tasks.\")\n",
        "        return\n",
        "\n",
        "    # Step 3: Initialize MAML model\n",
        "    print(\"\\n3. Initializing MAML Transformer model...\")\n",
        "    input_shape = X.shape[1:]  # Feature dimensions\n",
        "    n_way = min(5, len(np.unique(y_multiclass)))  # Number of classes per task\n",
        "\n",
        "    maml_model = MAMLTransformer(\n",
        "        input_shape=input_shape,\n",
        "        n_way=n_way,\n",
        "        k_shot=5,\n",
        "        inner_lr=0.01,\n",
        "        meta_lr=0.001,\n",
        "        meta_batch_size=16,\n",
        "        num_inner_updates=5,\n",
        "        embed_dim=128,\n",
        "        num_heads=4,\n",
        "        ff_dim=256,\n",
        "        num_transformer_blocks=3,\n",
        "        mlp_units=[64, 32],\n",
        "        dropout=0.1\n",
        "    )\n",
        "\n",
        "    print(f\"Model initialized with {n_way}-way classification\")\n",
        "    print(f\"Input shape: {input_shape}\")\n",
        "\n",
        "    # Step 4: Meta-training\n",
        "    print(\"\\n4. Starting meta-training...\")\n",
        "    trainer = MAMLTrainer(\n",
        "        maml_model=maml_model,\n",
        "        train_tasks=train_tasks,\n",
        "        val_tasks=val_tasks,\n",
        "        test_tasks=test_tasks,\n",
        "        meta_epochs=1000,  # Reduced for demo\n",
        "        meta_batch_size=16,\n",
        "        eval_interval=50,\n",
        "        early_stopping_patience=5,\n",
        "        log_dir='logs/maml_transformer'\n",
        "    )\n",
        "\n",
        "    history = trainer.train()\n",
        "\n",
        "    # Step 5: Visualize training process\n",
        "    print(\"\\n5. Visualizing training history...\")\n",
        "    trainer.visualize_training()\n",
        "\n",
        "    # Step 6: Adaptation analysis\n",
        "    print(\"\\n6. Analyzing adaptation to novel attacks...\")\n",
        "    # Select a random test task for analysis\n",
        "    random_task_idx = np.random.randint(len(test_tasks))\n",
        "    random_task = test_tasks[random_task_idx]\n",
        "\n",
        "    print(f\"Analyzing adaptation curve for task {random_task_idx}\")\n",
        "    adaptation_curve = trainer.plot_adaptation_curve(random_task)\n",
        "\n",
        "    # Step 7: Network security analysis\n",
        "    print(\"\\n7. Performing network security analysis...\")\n",
        "    security_analyzer = NetworkSecurityAnalyzer(\n",
        "        maml_model=maml_model,\n",
        "        data_processor=data_processor,\n",
        "        log_dir='logs/maml_transformer'\n",
        "    )\n",
        "\n",
        "    # Find indices for each attack type\n",
        "    if y_multiclass is not None:\n",
        "        attack_types = np.unique(y_multiclass)\n",
        "        normal_indices = np.where(y_binary == 0)[0]\n",
        "\n",
        "        # Skip normal class (usually labeled as 0)\n",
        "        for attack_idx in attack_types:\n",
        "            if attack_idx == 0:  # Skip normal class\n",
        "                continue\n",
        "\n",
        "            attack_name = f\"Attack Type {attack_idx}\"\n",
        "            print(f\"\\nAnalyzing novel attack detection: {attack_name}\")\n",
        "\n",
        "            # Get indices for this attack type\n",
        "            attack_indices = np.where(y_multiclass == attack_idx)[0]\n",
        "\n",
        "            if len(attack_indices) < 10:\n",
        "                print(f\"Not enough samples for attack type {attack_idx}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            # Analyze novel attack detection\n",
        "            results = security_analyzer.analyze_novel_attack(\n",
        "                X, y_binary, attack_indices, normal_indices, n_shot=5\n",
        "            )\n",
        "\n",
        "            print(f\"Best adaptation steps: {results['best_steps']}\")\n",
        "            print(f\"Best F1 score: {results['best_f1']:.4f}\")\n",
        "\n",
        "    # Step 8: Cross-attack analysis\n",
        "    print(\"\\n8. Analyzing performance across attack types...\")\n",
        "    # Create tasks for different attack types\n",
        "    attack_tasks = []\n",
        "    attack_names = []\n",
        "\n",
        "    if y_multiclass is not None:\n",
        "        for attack_idx in attack_types:\n",
        "            if attack_idx == 0:  # Skip normal class\n",
        "                continue\n",
        "\n",
        "            # Create a binary classification task (normal vs this attack)\n",
        "            attack_indices = np.where(y_multiclass == attack_idx)[0]\n",
        "\n",
        "            if len(attack_indices) < 10:\n",
        "                continue\n",
        "\n",
        "            # Select 5 examples for support and 15 for query\n",
        "            support_attack = attack_indices[:5]\n",
        "            query_attack = attack_indices[5:20]\n",
        "\n",
        "            # Select normal examples\n",
        "            support_normal = normal_indices[:5]\n",
        "            query_normal = normal_indices[5:20]\n",
        "\n",
        "            # Create support and query sets\n",
        "            support_indices = np.concatenate([support_normal, support_attack])\n",
        "            query_indices = np.concatenate([query_normal, query_attack])\n",
        "\n",
        "            # Create binary labels\n",
        "            support_y = np.concatenate([np.zeros(5), np.ones(5)])\n",
        "            query_y = np.concatenate([np.zeros(15), np.ones(15)])\n",
        "\n",
        "            # Shuffle support set\n",
        "            support_shuffle = np.arange(len(support_y))\n",
        "            np.random.shuffle(support_shuffle)\n",
        "            support_X = X[support_indices][support_shuffle]\n",
        "            support_y = support_y[support_shuffle]\n",
        "\n",
        "            # Create task\n",
        "            task = {\n",
        "                'support_X': support_X,\n",
        "                'support_y': support_y,\n",
        "                'query_X': X[query_indices],\n",
        "                'query_y': query_y,\n",
        "                'n_way': 2,\n",
        "                'k_shot': 5\n",
        "            }\n",
        "\n",
        "            attack_tasks.append(task)\n",
        "            attack_names.append(f\"Attack {attack_idx}\")\n",
        "\n",
        "    if attack_tasks:\n",
        "        performance = security_analyzer.analyze_attack_types(attack_tasks, attack_names)\n",
        "\n",
        "        print(\"\\nPerformance across attack types:\")\n",
        "        for name, acc, f1 in zip(performance['attack_names'], performance['accuracies'], performance['f1_scores']):\n",
        "            print(f\"{name}: Accuracy={acc:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "    # Step 9: Attention visualization\n",
        "    print(\"\\n9. Visualizing attention weights for explainability...\")\n",
        "    security_analyzer.visualize_attention_weights(X, y_multiclass if y_multiclass is not None else y_binary)\n",
        "\n",
        "    print(\"\\nDemo completed successfully!\")\n",
        "    return maml_model, trainer, security_analyzer\n",
        "\n",
        "\n",
        "# Main function to run the entire pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    # Set smaller figures for Jupyter notebooks if needed\n",
        "    plt.rcParams['figure.figsize'] = (10, 6)\n",
        "\n",
        "    # Run the complete demo\n",
        "    maml_model, trainer, analyzer = run_demo()"
      ]
    }
  ]
}