{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhbIjOTzZW7S"
      },
      "outputs": [],
      "source": [
        "#############################################################\n",
        "# Network Security Scenario Analysis\n",
        "#############################################################\n",
        "\n",
        "class NetworkSecurityAnalyzer:\n",
        "    def __init__(self, maml_model, data_processor, log_dir='logs'):\n",
        "        self.maml_model = maml_model\n",
        "        self.data_processor = data_processor\n",
        "        self.log_dir = log_dir\n",
        "        os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "    def analyze_novel_attack(self, X, y, attack_indices, normal_indices, n_shot=5):\n",
        "        \"\"\"\n",
        "        Analyze the model's ability to detect a novel attack type\n",
        "\n",
        "        Args:\n",
        "            X: Feature matrix\n",
        "            y: Binary labels\n",
        "            attack_indices: Indices of examples of the novel attack type\n",
        "            normal_indices: Indices of normal traffic\n",
        "            n_shot: Number of examples to use for adaptation\n",
        "        \"\"\"\n",
        "        # Ensure we have enough examples\n",
        "        if len(attack_indices) < n_shot * 2:\n",
        "            print(f\"Warning: Not enough attack examples. Using {len(attack_indices) // 2} shots instead.\")\n",
        "            n_shot = len(attack_indices) // 2\n",
        "\n",
        "        # Split attack indices into support and query sets\n",
        "        attack_support_indices = attack_indices[:n_shot]\n",
        "        attack_query_indices = attack_indices[n_shot:2*n_shot]\n",
        "\n",
        "        # Select normal examples for support and query sets\n",
        "        normal_support_indices = np.random.choice(normal_indices, n_shot, replace=False)\n",
        "        normal_query_indices = np.random.choice(\n",
        "            [i for i in normal_indices if i not in normal_support_indices],\n",
        "            n_shot,\n",
        "            replace=False\n",
        "        )\n",
        "\n",
        "        # Create binary classification task (normal vs attack)\n",
        "        support_indices = np.concatenate([normal_support_indices, attack_support_indices])\n",
        "        query_indices = np.concatenate([normal_query_indices, attack_query_indices])\n",
        "\n",
        "        support_X = X[support_indices]\n",
        "        support_y = np.concatenate([np.zeros(n_shot), np.ones(n_shot)])\n",
        "        query_X = X[query_indices]\n",
        "        query_y = np.concatenate([np.zeros(n_shot), np.ones(n_shot)])\n",
        "\n",
        "        # Shuffle support set\n",
        "        support_shuffle = np.arange(len(support_y))\n",
        "        np.random.shuffle(support_shuffle)\n",
        "        support_X = support_X[support_shuffle]\n",
        "        support_y = support_y[support_shuffle]\n",
        "\n",
        "        # Create task dictionary\n",
        "        task = {\n",
        "            'support_X': support_X,\n",
        "            'support_y': support_y,\n",
        "            'query_X': query_X,\n",
        "            'query_y': query_y,\n",
        "            'n_way': 2,  # Binary classification\n",
        "            'k_shot': n_shot\n",
        "        }\n",
        "\n",
        "        # Evaluate adaptation performance\n",
        "        accuracies = []\n",
        "        precisions = []\n",
        "        recalls = []\n",
        "        f1_scores = []\n",
        "        confusion_matrices = []\n",
        "\n",
        "        update_steps = [0, 1, 3, 5, 10]\n",
        "\n",
        "        for steps in update_steps:\n",
        "            # Adapt the model to the task\n",
        "            adapted_model = self.maml_model.adapt_to_task(support_X, support_y, num_inner_updates=steps)\n",
        "\n",
        "            # Make predictions on query set\n",
        "            query_logits = adapted_model(query_X, training=False)\n",
        "            pred_y = tf.argmax(query_logits, axis=1).numpy()\n",
        "\n",
        "            # Calculate metrics\n",
        "            accuracy = np.mean(pred_y == query_y)\n",
        "            cm = confusion_matrix(query_y, pred_y)\n",
        "\n",
        "            # Calculate precision, recall, and F1 for the attack class (label 1)\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "            accuracies.append(accuracy)\n",
        "            precisions.append(precision)\n",
        "            recalls.append(recall)\n",
        "            f1_scores.append(f1)\n",
        "            confusion_matrices.append(cm)\n",
        "\n",
        "        # Plot adaptation results\n",
        "        self._plot_adaptation_metrics(update_steps, accuracies, precisions, recalls, f1_scores)\n",
        "\n",
        "        # Plot confusion matrix for best step\n",
        "        best_idx = np.argmax(f1_scores)\n",
        "        self._plot_confusion_matrix(confusion_matrices[best_idx], ['Normal', 'Attack'])\n",
        "\n",
        "        return {\n",
        "            'accuracies': accuracies,\n",
        "            'precisions': precisions,\n",
        "            'recalls': recalls,\n",
        "            'f1_scores': f1_scores,\n",
        "            'best_steps': update_steps[best_idx],\n",
        "            'best_f1': f1_scores[best_idx]\n",
        "        }\n",
        "\n",
        "    def _plot_adaptation_metrics(self, steps, accuracies, precisions, recalls, f1_scores):\n",
        "        \"\"\"Plot adaptation metrics vs gradient steps\"\"\"\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        plt.plot(steps, accuracies, 'o-', label='Accuracy', linewidth=2)\n",
        "        plt.plot(steps, precisions, 's-', label='Precision', linewidth=2)\n",
        "        plt.plot(steps, recalls, '^-', label='Recall', linewidth=2)\n",
        "        plt.plot(steps, f1_scores, 'D-', label='F1 Score', linewidth=2)\n",
        "\n",
        "        plt.title('Attack Detection Performance vs Adaptation Steps')\n",
        "        plt.xlabel('Number of Gradient Updates')\n",
        "        plt.ylabel('Metric Value')\n",
        "        plt.legend()\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        plt.savefig(os.path.join(self.log_dir, 'adaptation_metrics.png'), dpi=300)\n",
        "        plt.show()\n",
        "\n",
        "    def _plot_confusion_matrix(self, cm, classes):\n",
        "        \"\"\"Plot confusion matrix\"\"\"\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(self.log_dir, 'confusion_matrix.png'), dpi=300)\n",
        "        plt.show()\n",
        "\n",
        "    def analyze_attack_types(self, tasks, attack_names=None):\n",
        "        \"\"\"\n",
        "        Analyze performance across different attack types\n",
        "\n",
        "        Args:\n",
        "            tasks: List of few-shot tasks for different attack types\n",
        "            attack_names: List of attack type names corresponding to tasks\n",
        "        \"\"\"\n",
        "        if attack_names is None:\n",
        "            attack_names = [f\"Attack Type {i+1}\" for i in range(len(tasks))]\n",
        "\n",
        "        n_attacks = len(tasks)\n",
        "        accuracies = []\n",
        "        f1_scores = []\n",
        "\n",
        "        for i, task in enumerate(tasks):\n",
        "            # Adapt the model to the task\n",
        "            adapted_model = self.maml_model.adapt_to_task(\n",
        "                task['support_X'], task['support_y'], num_inner_updates=5\n",
        "            )\n",
        "\n",
        "            # Make predictions on query set\n",
        "            query_X = task['query_X']\n",
        "            query_y = task['query_y']\n",
        "            query_logits = adapted_model(query_X, training=False)\n",
        "            pred_y = tf.argmax(query_logits, axis=1).numpy()\n",
        "\n",
        "            # Calculate metrics\n",
        "            accuracy = np.mean(pred_y == query_y)\n",
        "            cm = confusion_matrix(query_y, pred_y)\n",
        "\n",
        "            # For binary classification (assuming class 1 is the attack)\n",
        "            if task['n_way'] == 2:\n",
        "                tn, fp, fn, tp = cm.ravel()\n",
        "                precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "                recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "                f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "            else:\n",
        "                # For multiclass, use macro-averaged F1\n",
        "                report = classification_report(query_y, pred_y, output_dict=True)\n",
        "                f1 = report['macro avg']['f1-score']\n",
        "\n",
        "            accuracies.append(accuracy)\n",
        "            f1_scores.append(f1)\n",
        "\n",
        "        # Plot results\n",
        "        self._plot_attack_performance(attack_names, accuracies, f1_scores)\n",
        "\n",
        "        return {\n",
        "            'attack_names': attack_names,\n",
        "            'accuracies': accuracies,\n",
        "            'f1_scores': f1_scores\n",
        "        }\n",
        "\n",
        "    def _plot_attack_performance(self, attack_names, accuracies, f1_scores):\n",
        "        \"\"\"Plot performance across different attack types\"\"\"\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        x = np.arange(len(attack_names))\n",
        "        width = 0.35\n",
        "\n",
        "        plt.bar(x - width/2, accuracies, width, label='Accuracy')\n",
        "        plt.bar(x + width/2, f1_scores, width, label='F1 Score')\n",
        "\n",
        "        plt.xlabel('Attack Type')\n",
        "        plt.ylabel('Score')\n",
        "        plt.title('Performance Across Different Attack Types')\n",
        "        plt.xticks(x, attack_names, rotation=45, ha='right')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "        plt.savefig(os.path.join(self.log_dir, 'attack_performance.png'), dpi=300)\n",
        "        plt.show()\n",
        "\n",
        "    def visualize_attention_weights(self, X, y, attack_type_idx=None):\n",
        "        \"\"\"\n",
        "        Visualize attention weights to explain model decisions\n",
        "\n",
        "        Args:\n",
        "            X: Feature matrix\n",
        "            y: Labels\n",
        "            attack_type_idx: Optional index of attack type to visualize\n",
        "        \"\"\"\n",
        "        # Get a sample\n",
        "        if attack_type_idx is not None:\n",
        "            sample_idx = np.where(y == attack_type_idx)[0][0]\n",
        "        else:\n",
        "            sample_idx = np.random.choice(len(y))\n",
        "\n",
        "        sample_X = X[sample_idx:sample_idx+1]\n",
        "\n",
        "        # Create a transformer model with accessible attention weights\n",
        "        input_shape = X.shape[1:]\n",
        "        embed_dim = self.maml_model.embed_dim\n",
        "        num_heads = self.maml_model.num_heads\n",
        "        ff_dim = self.maml_model.ff_dim\n",
        "\n",
        "        # A simplified transformer model for visualization\n",
        "        inputs = layers.Input(shape=input_shape)\n",
        "        x = layers.Dense(embed_dim)(inputs)\n",
        "        x = tf.expand_dims(x, axis=1)  # Add sequence dimension\n",
        "\n",
        "        # Add positional encoding\n",
        "        x = PositionalEncoding(position=50, d_model=embed_dim)(x)\n",
        "\n",
        "        # Use the first transformer block for visualization\n",
        "        attention_layer = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        attn_output = attention_layer(x, x)\n",
        "\n",
        "        # Create the model\n",
        "        vis_model = keras.Model(inputs=inputs, outputs=attn_output)\n",
        "\n",
        "        # Copy weights from trained model (first layer only)\n",
        "        vis_model.layers[1].set_weights(self.maml_model.model.layers[1].get_weights())\n",
        "\n",
        "        # Run the model to get attention outputs\n",
        "        attention_output = vis_model(sample_X)\n",
        "\n",
        "        # Feature names (for visualization)\n",
        "        if hasattr(self.data_processor, 'X_columns'):\n",
        "            feature_names = self.data_processor.X_columns\n",
        "        else:\n",
        "            feature_names = [f\"Feature_{i}\" for i in range(input_shape[0])]\n",
        "\n",
        "        # Plot attention heatmap\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        sns.heatmap(attention_output[0].numpy(), cmap='viridis')\n",
        "        plt.title(f\"Attention Heatmap for Sample (Class {y[sample_idx]})\")\n",
        "        plt.xlabel(\"Embedded Features\")\n",
        "        plt.ylabel(\"Sequence Position\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(self.log_dir, 'attention_heatmap.png'), dpi=300)\n",
        "        plt.show()\n",
        "\n",
        "        # Return the most important features based on attention\n",
        "        feature_importance = attention_output[0].numpy().mean(axis=1).flatten()\n",
        "        top_k = 10  # Top k important features\n",
        "        top_indices = np.argsort(feature_importance)[-top_k:]\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.barh(np.array(feature_names)[top_indices], feature_importance[top_indices])\n",
        "        plt.xlabel(\"Average Attention\")\n",
        "        plt.ylabel(\"Feature\")\n",
        "        plt.title(\"Top Features by Attention Weight\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(self.log_dir, 'feature_importance.png'), dpi=300)\n",
        "        plt.show()\n"
      ]
    }
  ]
}